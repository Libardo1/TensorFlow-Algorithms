{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HMM(object):\n",
    "\n",
    "    \"\"\"\n",
    "    A class for Hidden Markov Models.\n",
    "\n",
    "    The model attributes are:\n",
    "    - K :: the number of states\n",
    "    - P :: the K by K transition matrix (from state i to state j,\n",
    "        (i, j) in [1..K])\n",
    "    - p0 :: the initial distribution (defaults to starting in state 0)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, P, p0=None):\n",
    "        self.K = P.shape[0]\n",
    "\n",
    "        self.P = P\n",
    "        self.logP = np.log(self.P)\n",
    "\n",
    "        if p0 is None:\n",
    "            self.p0 = np.ones(self.K)\n",
    "            self.p0 /= sum(self.p0)\n",
    "        elif len(p0) != self.K:\n",
    "            raise ValueError(\n",
    "                'dimensions of p0 {} must match P[0] {}'.format(\n",
    "                    p0.shape, P.shape[0]))\n",
    "        else:\n",
    "            self.p0 = p0\n",
    "        self.logp0 = np.log(self.p0)\n",
    "\n",
    "    def forward_backward(self, y):\n",
    "        \"\"\"\n",
    "        runs forward backward algorithm on state probabilities y\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        y : np.array : shape (T, K) where T is number of timesteps and\n",
    "            K is the number of states\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        (posterior, forward, backward)\n",
    "        posterior : list of length T of tensorflow graph nodes representing\n",
    "            the posterior probability of each state at each time step\n",
    "        forward : list of length T of tensorflow graph nodes representing\n",
    "            the forward probability of each state at each time step\n",
    "        backward : list of length T of tensorflow graph nodes representing\n",
    "            the backward probability of each state at each time step\n",
    "        \"\"\"\n",
    "        # set up\n",
    "        nT = y.shape[0]\n",
    "\n",
    "        posterior = np.zeros((nT, self.K))\n",
    "        forward = []\n",
    "        backward = np.zeros((nT + 1, self.K))\n",
    "\n",
    "        # forward pass\n",
    "        forward.append(\n",
    "            tf.ones((1, self.K), dtype=tf.float64) * (1.0 / self.K)\n",
    "        )\n",
    "        for t in range(nT):\n",
    "            # NOTE: np.matrix expands forward[t, :] into 2d and causes * to be\n",
    "            # matrix multiplies instead of element wise that an array would be\n",
    "            tmp = tf.mul(\n",
    "                tf.matmul(forward[t], self.P),\n",
    "                y[t]\n",
    "            )\n",
    "\n",
    "            forward.append(tmp / tf.reduce_sum(tmp))\n",
    "\n",
    "        # backward pass\n",
    "        backward = [None] * (nT + 1)\n",
    "        backward[-1] = tf.ones((1, self.K), dtype=tf.float64) * (1.0 / self.K)\n",
    "        for t in range(nT, 0, -1):\n",
    "            tmp = tf.transpose(\n",
    "                tf.matmul(\n",
    "                    tf.matmul(self.P, tf.diag(y[t - 1])),\n",
    "                    tf.transpose(backward[t])\n",
    "                )\n",
    "            )\n",
    "            backward[t - 1] = tmp / tf.reduce_sum(tmp)\n",
    "\n",
    "        # remove initial/final probabilities\n",
    "        forward = forward[1:]\n",
    "        backward = backward[:-1]\n",
    "\n",
    "        # combine and normalize\n",
    "        posterior = [f * b for f, b in zip(forward, backward)]\n",
    "        posterior = [p / tf.reduce_sum(p) for p in posterior]\n",
    "\n",
    "        return posterior, forward, backward\n",
    "\n",
    "    def _viterbi_partial_forward(self, scores):\n",
    "        # first convert scores into shape [K, 1]\n",
    "        # then concatenate K of them into shape [K, K]\n",
    "        expanded_scores = tf.concat(\n",
    "            1, [tf.expand_dims(scores, 1)] * self.K\n",
    "        )\n",
    "        return expanded_scores + self.logP\n",
    "\n",
    "    def viterbi_decode(self, y, nT):\n",
    "        \"\"\"\n",
    "        Runs viterbi decode on state probabilies y.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        y : np.array : shape (T, K) where T is number of timesteps and\n",
    "            K is the number of states\n",
    "        nT : int : number of timesteps in y\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        (s, pathScores)\n",
    "        s : list of length T of tensorflow ints : represents the most likely\n",
    "            state at each time step.\n",
    "        pathScores : list of length T of tensorflow tensor of length K\n",
    "            each value at (t, k) is the log likliehood score in state k at\n",
    "            time t.  sum(pathScores[t, :]) will not necessary == 1\n",
    "        \"\"\"\n",
    "\n",
    "        # pathStates and pathScores wil be of type tf.Tensor.  They\n",
    "        # are lists since tensorflow doesn't allow indexing, and the\n",
    "        # list and order are only really necessary to build the unrolled\n",
    "        # graph.  We never do any computation across all of time at once\n",
    "        pathStates = []\n",
    "        pathScores = []\n",
    "\n",
    "        # initialize\n",
    "        pathStates.append(None)\n",
    "        pathScores.append(self.logp0 + np.log(y[0]))\n",
    "\n",
    "        for t, yy in enumerate(y[1:]):\n",
    "            # propagate forward\n",
    "            tmpMat = self._viterbi_partial_forward(pathScores[t])\n",
    "\n",
    "            # the inferred state\n",
    "            pathStates.append(tf.argmax(tmpMat, 0))\n",
    "            pathScores.append(tf.reduce_max(tmpMat, 0) + np.log(yy))\n",
    "\n",
    "        # now backtrack viterbi to find states\n",
    "        s = [0] * nT\n",
    "        s[-1] = tf.argmax(pathScores[-1], 0)\n",
    "        for t in range(nT - 1, 0, -1):\n",
    "            s[t - 1] = tf.gather(pathStates[t], s[t])\n",
    "\n",
    "        return s, pathScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def latch_P():\n",
    "    P = np.array([[0.5, 0.5], [0.0, 1.0]])\n",
    "    # P = np.array([[0.5, 0.5], [0.5, 0.5]])\n",
    "    # P = np.array([[0.5, 0.5], [0.0000000001, 0.9999999999]])\n",
    "    # P = np.array([[0.5, 0.5], [1e-50, 1 - 1e-50]])\n",
    "\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            print('from', i, 'to', j, P[i, j])\n",
    "    return P\n",
    "\n",
    "def fair_P():\n",
    "    return np.array([[0.5, 0.5], [0.5, 0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5,  0.5],\n",
       "       [ 0.5,  0.5]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair_P()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hmm_tf_fair(fair_P):\n",
    "    return HMM(fair_P)\n",
    "\n",
    "def hmm_tf_latch(latch_P):\n",
    "    return HMM(latch_P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lik(y):\n",
    "    \"\"\" given 1d vector of likliehoods length N, return matrix with\n",
    "    shape (N, 2) where (N, 0) is 1 - y and (N, 1) is y.\n",
    "\n",
    "    This makes it easy to convert a time series of probabilities\n",
    "    into 2 states, off/on, for a simple HMM.\n",
    "    \"\"\"\n",
    "\n",
    "    liklihood = np.array([y, y], float).T\n",
    "    liklihood[:, 0] = 1 - liklihood[:, 0]\n",
    "    return liklihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_hmm_tf_fair_forward_backward(hmm_tf_fair):\n",
    "    y = lik(np.array([0, 0, 1, 1]))\n",
    "\n",
    "    g_posterior, _, _ = hmm_tf_fair.forward_backward(y)\n",
    "    tf_posterior = np.concatenate(tf.Session().run(g_posterior))\n",
    "\n",
    "    print('tf_posterior: \\n', tf_posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_posterior: \n",
      " [[ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "test_hmm_tf_fair_forward_backward(hmm_tf_fair(fair_P()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_hmm_fair_forward_backward(hmm_fair):\n",
    "    y = lik(np.array([0, 0, 1, 1]))\n",
    "\n",
    "    posterior, f, b = hmm_fair.forward_backward(y)\n",
    "\n",
    "    # if P is filled with 0.5, the only thing that matters is the emission\n",
    "    # liklihood.  assert that the posterior is = the liklihood of y\n",
    "    for i, yi in enumerate(y):\n",
    "        liklihood = yi / np.sum(yi)\n",
    "        assert np.isclose(posterior[i, :], liklihood).all()\n",
    "\n",
    "    # assert that posterior for any given t sums to 1\n",
    "    assert np.isclose(np.sum(posterior, 1), 1).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_hmm_latch_two_step_no_noise(hmm_latch):\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            y = [i, i, j, j]\n",
    "            # y = [i, j]\n",
    "\n",
    "            if i == 1 and j == 0:\n",
    "                continue\n",
    "\n",
    "            print('*'*80)\n",
    "            print(y)\n",
    "            states, scores = hmm_latch.viterbi_decode(lik(y))\n",
    "\n",
    "            assert all(states == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_hmm_tf_partial_forward(hmm_tf_latch):\n",
    "    scoress = [\n",
    "        np.log(np.array([0, 1])),\n",
    "        np.log(np.array([1, 0])),\n",
    "        np.log(np.array([0.25, 0.75])),\n",
    "        np.log(np.array([0.5, 0.5])),\n",
    "    ]\n",
    "\n",
    "    for scores in scoress:\n",
    "        tf_ret = tf.Session().run(\n",
    "            hmm_tf_latch._viterbi_partial_forward(scores))\n",
    "        print(tf_ret)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from 0 to 0 0.5\n",
      "from 0 to 1 0.5\n",
      "from 1 to 0 0.0\n",
      "from 1 to 1 1.0\n",
      "[[-inf -inf]\n",
      " [-inf   0.]]\n",
      "[[-0.69314718 -0.69314718]\n",
      " [       -inf        -inf]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marvinbertin/anaconda/envs/TensorFlow-env/lib/python2.7/site-packages/ipykernel/__main__.py:17: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/marvinbertin/anaconda/envs/TensorFlow-env/lib/python2.7/site-packages/ipykernel/__main__.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  app.launch_new_instance()\n",
      "/Users/marvinbertin/anaconda/envs/TensorFlow-env/lib/python2.7/site-packages/ipykernel/__main__.py:4: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.07944154 -2.07944154]\n",
      " [       -inf -0.28768207]]\n",
      "[[-1.38629436 -1.38629436]\n",
      " [       -inf -0.69314718]]\n"
     ]
    }
   ],
   "source": [
    "test_hmm_tf_partial_forward(hmm_tf_latch(latch_P()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_hmm_tf_viterbi_decode(hmm_tf_latch):\n",
    "    ys = [\n",
    "        lik(np.array([0, 0])),\n",
    "        lik(np.array([1, 1])),\n",
    "        lik(np.array([0, 1])),\n",
    "        lik(np.array([0, 0.25, 0.5, 0.75, 1])),\n",
    "    ]\n",
    "\n",
    "    for y in ys:\n",
    "        print(y)\n",
    "\n",
    "        tf_s_graph, tf_scores_graph = hmm_tf_latch.viterbi_decode(y, len(y))\n",
    "        tf_s = tf.Session().run(tf_s_graph)\n",
    "        tf_scores = [tf_scores_graph[0]]\n",
    "        tf_scores.extend([tf.Session().run(g) for g in tf_scores_graph[1:]])\n",
    "        print(np.array(tf_scores))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from 0 to 0 0.5\n",
      "from 0 to 1 0.5\n",
      "from 1 to 0 0.0\n",
      "from 1 to 1 1.0\n",
      "[[ 1.  0.]\n",
      " [ 1.  0.]]\n",
      "[[-0.69314718        -inf]\n",
      " [-1.38629436        -inf]]\n",
      "\n",
      "[[ 0.  1.]\n",
      " [ 0.  1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marvinbertin/anaconda/envs/TensorFlow-env/lib/python2.7/site-packages/ipykernel/__main__.py:17: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/marvinbertin/anaconda/envs/TensorFlow-env/lib/python2.7/site-packages/ipykernel/__main__.py:129: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/marvinbertin/anaconda/envs/TensorFlow-env/lib/python2.7/site-packages/ipykernel/__main__.py:137: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[       -inf -0.69314718]\n",
      " [       -inf -0.69314718]]\n",
      "\n",
      "[[ 1.  0.]\n",
      " [ 0.  1.]]\n",
      "[[-0.69314718        -inf]\n",
      " [       -inf -1.38629436]]\n",
      "\n",
      "[[ 1.    0.  ]\n",
      " [ 0.75  0.25]\n",
      " [ 0.5   0.5 ]\n",
      " [ 0.25  0.75]\n",
      " [ 0.    1.  ]]\n",
      "[[-0.69314718        -inf]\n",
      " [-1.67397643 -2.77258872]\n",
      " [-3.06027079 -3.06027079]\n",
      " [-5.13971234 -3.34795287]\n",
      " [       -inf -3.34795287]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_hmm_tf_viterbi_decode(hmm_tf_latch(latch_P()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
