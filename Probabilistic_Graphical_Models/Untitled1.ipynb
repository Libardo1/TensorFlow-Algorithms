{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HMM(object):\n",
    "    \"\"\"\n",
    "    A class for Hidden Markov Models.\n",
    "\n",
    "    The model attributes are:\n",
    "    - K :: the number of states\n",
    "    - P :: the K by K transition matrix (from state i to state j,\n",
    "        (i, j) in [1..K])\n",
    "    - p0 :: the initial distribution (defaults to starting in state 0)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, P, p0=None):\n",
    "        self.K = P.shape[0]\n",
    "\n",
    "        self.P = P\n",
    "        self.logP = np.log(self.P)\n",
    "\n",
    "        if p0 is None:\n",
    "            self.p0 = np.ones(self.K)\n",
    "            self.p0 /= sum(self.p0)\n",
    "        elif len(p0) != self.K:\n",
    "            raise ValueError(\n",
    "                'dimensions of p0 {} must match P[0] {}'.format(\n",
    "                    p0.shape, P.shape[0]))\n",
    "        else:\n",
    "            self.p0 = p0\n",
    "        self.logp0 = np.log(self.p0)\n",
    "\n",
    "\n",
    "class HMMNumpy(HMM):\n",
    "\n",
    "    def forward_backward(self, y):\n",
    "        # set up\n",
    "        nT = y.shape[0]\n",
    "        posterior = np.zeros((nT, self.K))\n",
    "        forward = np.zeros((nT + 1, self.K))\n",
    "        backward = np.zeros((nT + 1, self.K))\n",
    "\n",
    "        # forward pass\n",
    "        forward[0, :] = 1.0 / self.K\n",
    "        for t in range(nT):\n",
    "            tmp = np.multiply(\n",
    "                np.matmul(forward[t, :], self.P),\n",
    "                y[t]\n",
    "            )\n",
    "\n",
    "            forward[t + 1, :] = tmp / np.sum(tmp)\n",
    "\n",
    "        # backward pass\n",
    "        backward[-1, :] = 1.0\n",
    "        for t in range(nT, 0, -1):\n",
    "            tmp = np.matmul(\n",
    "                np.matmul(\n",
    "                    self.P, np.diag(y[t - 1])\n",
    "                ),\n",
    "                backward[t, :].transpose()\n",
    "            ).transpose()\n",
    "\n",
    "            backward[t - 1, :] = tmp / np.sum(tmp)\n",
    "\n",
    "        # remove initial/final probabilities\n",
    "        forward = forward[1:, :]\n",
    "        backward = backward[:-1, :]\n",
    "\n",
    "        # combine and normalize\n",
    "        posterior = np.array(forward) * np.array(backward)\n",
    "        # [:,None] expands sum to be correct size\n",
    "        posterior = posterior / np.sum(posterior, 1)[:, None]\n",
    "\n",
    "        return posterior, forward, backward\n",
    "\n",
    "    def _viterbi_partial_forward(self, scores):\n",
    "        tmpMat = np.zeros((self.K, self.K))\n",
    "        for i in range(self.K):\n",
    "            for j in range(self.K):\n",
    "                tmpMat[i, j] = scores[i] + self.logP[i, j]\n",
    "        return tmpMat\n",
    "\n",
    "    def viterbi_decode(self, y):\n",
    "        y = np.array(y)\n",
    "\n",
    "        nT = y.shape[0]\n",
    "\n",
    "        pathStates = np.zeros((nT, self.K), dtype=np.int)\n",
    "        pathScores = np.zeros((nT, self.K))\n",
    "\n",
    "        # initialize\n",
    "        pathScores[0] = self.logp0 + np.log(y[0])\n",
    "\n",
    "        for t, yy in enumerate(y[1:]):\n",
    "            # propagate forward\n",
    "            tmpMat = self._viterbi_partial_forward(pathScores[t])\n",
    "\n",
    "            # the inferred state\n",
    "            pathStates[t + 1] = np.argmax(tmpMat, 0)\n",
    "            pathScores[t + 1] = np.max(tmpMat, 0) + np.log(yy)\n",
    "\n",
    "        # now backtrack viterbi to find states\n",
    "        s = np.zeros(nT, dtype=np.int)\n",
    "        s[-1] = np.argmax(pathScores[-1])\n",
    "        for t in range(nT - 1, 0, -1):\n",
    "            s[t - 1] = pathStates[t, s[t]]\n",
    "\n",
    "        return s, pathScores\n",
    "\n",
    "\n",
    "class HMMTensorflow(HMM):\n",
    "\n",
    "    def forward_backward(self, y):\n",
    "        \"\"\"\n",
    "        runs forward backward algorithm on state probabilities y\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        y : np.array : shape (T, K) where T is number of timesteps and\n",
    "            K is the number of states\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        (posterior, forward, backward)\n",
    "        posterior : list of length T of tensorflow graph nodes representing\n",
    "            the posterior probability of each state at each time step\n",
    "        forward : list of length T of tensorflow graph nodes representing\n",
    "            the forward probability of each state at each time step\n",
    "        backward : list of length T of tensorflow graph nodes representing\n",
    "            the backward probability of each state at each time step\n",
    "        \"\"\"\n",
    "        # set up\n",
    "        nT = y.shape[0]\n",
    "\n",
    "        posterior = np.zeros((nT, self.K))\n",
    "        forward = []\n",
    "        backward = np.zeros((nT + 1, self.K))\n",
    "\n",
    "        # forward pass\n",
    "        forward.append(\n",
    "            tf.ones((1, self.K), dtype=tf.float64) * (1.0 / self.K)\n",
    "        )\n",
    "        for t in range(nT):\n",
    "            # NOTE: np.matrix expands forward[t, :] into 2d and causes * to be\n",
    "            # matrix multiplies instead of element wise that an array would be\n",
    "            tmp = tf.mul(\n",
    "                tf.matmul(forward[t], self.P),\n",
    "                y[t]\n",
    "            )\n",
    "            tmp = tf.squeeze(tmp)\n",
    "            forward.append(tmp / tf.reduce_sum(tmp))\n",
    "\n",
    "        # backward pass\n",
    "        backward = [None] * (nT + 1)\n",
    "        backward[-1] = tf.ones((1, self.K), dtype=tf.float64) * (1.0 / self.K)\n",
    "        for t in range(nT, 0, -1):\n",
    "            tmp = tf.transpose(\n",
    "                tf.matmul(\n",
    "                    tf.matmul(self.P, tf.diag(y[t - 1])),\n",
    "                    tf.transpose(backward[t])\n",
    "                )\n",
    "            )\n",
    "            tmp = tf.squeeze(tmp)\n",
    "            backward[t - 1] = tmp / tf.reduce_sum(tmp)\n",
    "\n",
    "        # remove initial/final probabilities\n",
    "        forward = forward[1:]\n",
    "        backward = backward[:-1]\n",
    "\n",
    "        # combine and normalize\n",
    "        posterior = [f * b for f, b in zip(forward, backward)]\n",
    "        posterior = [p / tf.reduce_sum(p) for p in posterior]\n",
    "\n",
    "        return posterior, forward, backward\n",
    "\n",
    "    def _viterbi_partial_forward(self, scores):\n",
    "        # first convert scores into shape [K, 1]\n",
    "        # then concatenate K of them into shape [K, K]\n",
    "        expanded_scores = tf.concat(\n",
    "            1, [tf.expand_dims(scores, 1)] * self.K\n",
    "        )\n",
    "#         print(expanded_scores.eval(session = tf.Session()))\n",
    "#         print()\n",
    "#         print(self.logP)\n",
    "#         print()\n",
    "        return expanded_scores + self.logP\n",
    "\n",
    "    def viterbi_decode(self, y, nT):\n",
    "        \"\"\"\n",
    "        Runs viterbi decode on state probabilies y.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        y : np.array : shape (T, K) where T is number of timesteps and\n",
    "            K is the number of states\n",
    "        nT : int : number of timesteps in y\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        (s, pathScores)\n",
    "        s : list of length T of tensorflow ints : represents the most likely\n",
    "            state at each time step.\n",
    "        pathScores : list of length T of tensorflow tensor of length K\n",
    "            each value at (t, k) is the log likliehood score in state k at\n",
    "            time t.  sum(pathScores[t, :]) will not necessary == 1\n",
    "        \"\"\"\n",
    "\n",
    "        # pathStates and pathScores wil be of type tf.Tensor.  They\n",
    "        # are lists since tensorflow doesn't allow indexing, and the\n",
    "        # list and order are only really necessary to build the unrolled\n",
    "        # graph.  We never do any computation across all of time at once\n",
    "        pathStates = []\n",
    "        pathScores = []\n",
    "\n",
    "        # initialize\n",
    "        pathStates.append(None)\n",
    "        pathScores.append(self.logp0 + np.log(y[0]))\n",
    "\n",
    "        for t, yy in enumerate(y[1:]):\n",
    "            # propagate forward\n",
    "            tmpMat = self._viterbi_partial_forward(pathScores[t])\n",
    "            print(tmpMat.eval(session = tf.Session()))\n",
    "            # the inferred state\n",
    "            pathStates.append(tf.argmax(tmpMat, 0))\n",
    "            pathScores.append(tf.reduce_max(tmpMat, 0) + np.log(yy))\n",
    "\n",
    "        # now backtrack viterbi to find states\n",
    "        s = [0] * nT\n",
    "        s[-1] = tf.argmax(pathScores[-1], 0)\n",
    "        for t in range(nT - 1, 0, -1):\n",
    "            s[t - 1] = tf.gather(pathStates[t], s[t])\n",
    "\n",
    "        return s, pathScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p0 = np.array([0.6, 0.4])\n",
    "\n",
    "emi = np.array([[0.5, 0.1],\n",
    "                [0.4, 0.3],\n",
    "                [0.1, 0.6]])\n",
    "\n",
    "trans = np.array([[0.7, 0.3],\n",
    "                  [0.4, 0.6]])\n",
    "\n",
    "states = {0:'Healthy', 1:'Fever'}\n",
    "obs = {0:'normal', 1:'cold', 2:'dizzy'}\n",
    "\n",
    "obs_seq = np.array([0, 1, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dptable(V):\n",
    "    print(\" \".join((\"%10d\" % i) for i in range(V.shape[0])))\n",
    "    for i, y in enumerate(V.T):\n",
    "        print(\"%.7s: \" % states[i] +\" \".join(\"%.7s\" % (\"%f\" % yy) for yy in y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.56064775 -2.40794561]\n",
      " [-4.13516656 -3.72970145]]\n",
      "[[-2.83361342 -3.68091128]\n",
      " [-4.52820914 -4.12274404]]\n",
      "Most likely States:  ['normal', 'normal', 'cold']\n",
      "         0          1          2\n",
      "Healthy: 0.30000 0.08400 0.00588\n",
      "Fever: 0.04000 0.02700 0.01512\n"
     ]
    }
   ],
   "source": [
    "tf_model = HMMTensorflow(trans, p0)\n",
    "\n",
    "y = emi[obs_seq]\n",
    "tf_s_graph, tf_scores_graph = tf_model.viterbi_decode(y, len(y))\n",
    "tf_s = tf.Session().run(tf_s_graph)\n",
    "print(\"Most likely States: \", [obs[s] for s in tf_s])\n",
    "\n",
    "tf_scores = [tf_scores_graph[0]]\n",
    "tf_scores.extend([tf.Session().run(g) for g in tf_scores_graph[1:]])\n",
    "pathScores = np.array(np.exp(tf_scores))\n",
    "dptable(pathScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most likely States:  ['normal', 'normal', 'cold']\n",
      "         0          1          2\n",
      "Healthy: 0.30000 0.08400 0.00588\n",
      "Fever: 0.04000 0.02700 0.01512\n"
     ]
    }
   ],
   "source": [
    "np_model = HMMNumpy(trans, p0)\n",
    "\n",
    "y = emi[obs_seq]\n",
    "np_states, np_scores = np_model.viterbi_decode(y)\n",
    "print(\"Most likely States: \",[obs[s] for s in np_states])\n",
    "pathScores = np.array(np.exp(np_scores))\n",
    "dptable(pathScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class HMM(object):\n",
    "    \"\"\"\n",
    "    A class for Hidden Markov Models.\n",
    "\n",
    "    The model attributes are:\n",
    "    - K :: the number of states\n",
    "    - P :: the K by K transition matrix (from state i to state j,\n",
    "        (i, j) in [1..K])\n",
    "    - p0 :: the initial distribution (defaults to starting in state 0)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, P, p0=None):\n",
    "        self.K = P.shape[0]\n",
    "\n",
    "        self.P = P\n",
    "        self.logP = np.log(self.P)\n",
    "\n",
    "        if p0 is None:\n",
    "            self.p0 = np.ones(self.K)\n",
    "            self.p0 /= sum(self.p0)\n",
    "        elif len(p0) != self.K:\n",
    "            raise ValueError(\n",
    "                'dimensions of p0 {} must match P[0] {}'.format(\n",
    "                    p0.shape, P.shape[0]))\n",
    "        else:\n",
    "            self.p0 = p0\n",
    "        self.logp0 = np.log(self.p0)\n",
    "\n",
    "\n",
    "class HMMTensorflow(HMM):\n",
    "\n",
    "    def forward_backward(self, y):\n",
    "        \"\"\"\n",
    "        runs forward backward algorithm on state probabilities y\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        y : np.array : shape (T, K) where T is number of timesteps and\n",
    "            K is the number of states\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        (posterior, forward, backward)\n",
    "        posterior : list of length T of tensorflow graph nodes representing\n",
    "            the posterior probability of each state at each time step\n",
    "        forward : list of length T of tensorflow graph nodes representing\n",
    "            the forward probability of each state at each time step\n",
    "        backward : list of length T of tensorflow graph nodes representing\n",
    "            the backward probability of each state at each time step\n",
    "        \"\"\"\n",
    "        # set up\n",
    "        nT = y.shape[0]\n",
    "\n",
    "        posterior = np.zeros((nT, self.K))\n",
    "        forward = []\n",
    "        backward = np.zeros((nT + 1, self.K))\n",
    "\n",
    "        # forward pass\n",
    "        forward.append(\n",
    "            tf.ones((1, self.K), dtype=tf.float64) * (1.0 / self.K)\n",
    "        )\n",
    "        for t in range(nT):\n",
    "            # NOTE: np.matrix expands forward[t, :] into 2d and causes * to be\n",
    "            # matrix multiplies instead of element wise that an array would be\n",
    "            tmp = tf.mul(\n",
    "                tf.matmul(forward[t], self.P),\n",
    "                y[t]\n",
    "            )\n",
    "\n",
    "            forward.append(tmp / tf.reduce_sum(tmp))\n",
    "\n",
    "        # backward pass\n",
    "        backward = [None] * (nT + 1)\n",
    "        backward[-1] = tf.ones((1, self.K), dtype=tf.float64) * (1.0 / self.K)\n",
    "        for t in range(nT, 0, -1):\n",
    "            tmp = tf.transpose(\n",
    "                tf.matmul(\n",
    "                    tf.matmul(self.P, tf.diag(y[t - 1])),\n",
    "                    tf.transpose(backward[t])\n",
    "                )\n",
    "            )\n",
    "            backward[t - 1] = tmp / tf.reduce_sum(tmp)\n",
    "\n",
    "        # remove initial/final probabilities\n",
    "        forward = forward[1:]\n",
    "        backward = backward[:-1]\n",
    "\n",
    "        # combine and normalize\n",
    "        posterior = [f * b for f, b in zip(forward, backward)]\n",
    "        posterior = [p / tf.reduce_sum(p) for p in posterior]\n",
    "\n",
    "        return posterior, forward, backward\n",
    "\n",
    "    def _viterbi_partial_forward(self, scores):\n",
    "        # first convert scores into shape [K, 1]\n",
    "        # then concatenate K of them into shape [K, K]\n",
    "        expanded_scores = tf.concat(\n",
    "            1, [tf.expand_dims(scores, 1)] * self.K\n",
    "        )\n",
    "        return expanded_scores + self.logP\n",
    "\n",
    "    def viterbi_decode(self, y, nT):\n",
    "        \"\"\"\n",
    "        Runs viterbi decode on state probabilies y.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        y : np.array : shape (T, K) where T is number of timesteps and\n",
    "            K is the number of states\n",
    "        nT : int : number of timesteps in y\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        (s, pathScores)\n",
    "        s : list of length T of tensorflow ints : represents the most likely\n",
    "            state at each time step.\n",
    "        pathScores : list of length T of tensorflow tensor of length K\n",
    "            each value at (t, k) is the log likliehood score in state k at\n",
    "            time t.  sum(pathScores[t, :]) will not necessary == 1\n",
    "        \"\"\"\n",
    "\n",
    "        # pathStates and pathScores wil be of type tf.Tensor.  They\n",
    "        # are lists since tensorflow doesn't allow indexing, and the\n",
    "        # list and order are only really necessary to build the unrolled\n",
    "        # graph.  We never do any computation across all of time at once\n",
    "        pathStates = []\n",
    "        pathScores = []\n",
    "\n",
    "        # initialize\n",
    "        pathStates.append(None)\n",
    "        pathScores.append(self.logp0 + np.log(y[0]))\n",
    "\n",
    "        for t, yy in enumerate(y[1:]):\n",
    "            # propagate forward\n",
    "            tmpMat = self._viterbi_partial_forward(pathScores[t])\n",
    "\n",
    "            # the inferred state\n",
    "            pathStates.append(tf.argmax(tmpMat, 0))\n",
    "            pathScores.append(tf.reduce_max(tmpMat, 0) + np.log(yy))\n",
    "\n",
    "        # now backtrack viterbi to find states\n",
    "        s = [0] * nT\n",
    "        s[-1] = tf.argmax(pathScores[-1], 0)\n",
    "        for t in range(nT - 1, 0, -1):\n",
    "            s[t - 1] = tf.gather(pathStates[t], s[t])\n",
    "\n",
    "        return s, pathScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p0 = np.array([0.5, 0.5])\n",
    "\n",
    "emi = np.array([[0.9, 0.2],\n",
    "                [0.1, 0.8]])\n",
    "\n",
    "trans = np.array([[0.7, 0.3],\n",
    "                  [0.3, 0.7]])\n",
    "\n",
    "states = {0:'rain', 1:'no_rain'}\n",
    "obs = {0:'umbrella', 1:'no_umbrella'}\n",
    "\n",
    "obs_seq = np.array([0, 0, 1, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape (6, 2) must have rank 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-bcd2cb2b6d66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# matrix multiplies instead of element wise that an array would be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     tmp = tf.mul(\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     )\n",
      "\u001b[0;32m/Users/marvinbertin/anaconda/envs/TensorFlow-env/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.pyc\u001b[0m in \u001b[0;36m_SliceHelper\u001b[0;34m(tensor, slice_spec)\u001b[0m\n\u001b[1;32m    165\u001b[0m       \u001b[0msizes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m       \u001b[0msqueeze_dims\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m   \u001b[0msliced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msqueeze_dims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msliced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msqueeze_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msqueeze_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marvinbertin/anaconda/envs/TensorFlow-env/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.pyc\u001b[0m in \u001b[0;36mslice\u001b[0;34m(input_, begin, size, name)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0mA\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m`\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m   \"\"\"\n\u001b[0;32m--> 217\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marvinbertin/anaconda/envs/TensorFlow-env/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.pyc\u001b[0m in \u001b[0;36m_slice\u001b[0;34m(input, begin, size, name)\u001b[0m\n\u001b[1;32m   1316\u001b[0m   \"\"\"\n\u001b[1;32m   1317\u001b[0m   return _op_def_lib.apply_op(\"Slice\", input=input, begin=begin, size=size,\n\u001b[0;32m-> 1318\u001b[0;31m                               name=name)\n\u001b[0m\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marvinbertin/anaconda/envs/TensorFlow-env/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.pyc\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    653\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    654\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    656\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_Restructure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_n_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marvinbertin/anaconda/envs/TensorFlow-env/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2154\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2155\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2156\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2157\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marvinbertin/anaconda/envs/TensorFlow-env/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1610\u001b[0m       raise RuntimeError(\"No shape function registered for standard op: %s\"\n\u001b[1;32m   1611\u001b[0m                          % op.type)\n\u001b[0;32m-> 1612\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1613\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1614\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/Users/marvinbertin/anaconda/envs/TensorFlow-env/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.pyc\u001b[0m in \u001b[0;36m_SliceShape\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    863\u001b[0m   \u001b[0mndims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbegin_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msizes_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mndims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m     \u001b[0minput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_has_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m   \u001b[0mbegin_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m   \u001b[0msizes_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marvinbertin/anaconda/envs/TensorFlow-env/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.pyc\u001b[0m in \u001b[0;36massert_has_rank\u001b[0;34m(self, rank)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \"\"\"\n\u001b[1;32m    604\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shape %s must have rank %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwith_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape (6, 2) must have rank 1"
     ]
    }
   ],
   "source": [
    "# Number of states\n",
    "S = trans.shape[0]\n",
    "# Emission probability\n",
    "E = tf.constant(emi, name='emission_matrix')\n",
    "# Transition matrix\n",
    "T = tf.constant(trans, name='transition_matrix')\n",
    "# Initial state vector\n",
    "T0 = tf.constant(p0, name='inital_state_vector')\n",
    "        \n",
    "# length of observed sequence\n",
    "N = len(obs_seq)\n",
    "\n",
    "# shape path Variables\n",
    "shape = [N, S]\n",
    "shape_ext = [N+1, S]\n",
    "# observed sequence\n",
    "x = tf.constant(obs_seq, name='observation_sequence')\n",
    "\n",
    "forward = tf.Variable(tf.zeros(shape_ext, dtype=tf.float64), name='forward')\n",
    "backward = tf.Variable(tf.zeros(shape_ext, dtype=tf.float64), name='backward')\n",
    "posteriror = tf.Variable(tf.zeros(shape, dtype=tf.float64), name='posteriror')\n",
    "\n",
    "# forward pass\n",
    "forward = tf.scatter_update(forward, 0, T0)\n",
    "\n",
    "for t in range(N):\n",
    "    # NOTE: np.matrix expands forward[t, :] into 2d and causes * to be\n",
    "    # matrix multiplies instead of element wise that an array would be\n",
    "    tmp = tf.mul(\n",
    "        tf.matmul(forward[t], self.P),\n",
    "        y[t]\n",
    "    )\n",
    "\n",
    "    forward.append(tmp / tf.reduce_sum(tmp))\n",
    "\n",
    "# backward pass\n",
    "backward = [None] * (nT + 1)\n",
    "backward[-1] = tf.ones((1, self.K), dtype=tf.float64) * (1.0 / self.K)\n",
    "for t in range(nT, 0, -1):\n",
    "    tmp = tf.transpose(\n",
    "        tf.matmul(\n",
    "            tf.matmul(self.P, tf.diag(y[t - 1])),\n",
    "            tf.transpose(backward[t])\n",
    "        )\n",
    "    )\n",
    "    backward[t - 1] = tmp / tf.reduce_sum(tmp)\n",
    "\n",
    "# remove initial/final probabilities\n",
    "forward = forward[1:]\n",
    "backward = backward[:-1]\n",
    "\n",
    "# combine and normalize\n",
    "posterior = tf.mul(forward, backward)\n",
    "# [:,None] expands sum to be correct size\n",
    "#posterior = posterior / np.sum(posterior, 1)[:, None]\n",
    "\n",
    "#posterior = [p / tf.reduce_sum(p) for p in posterior]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of states\n",
    "S = trans.shape[0]\n",
    "# Emission probability\n",
    "E = tf.constant(emi, name='emission_matrix')\n",
    "# Transition matrix\n",
    "T = tf.constant(trans, name='transition_matrix')\n",
    "# Initial state vector\n",
    "T0 = tf.constant(p0, name='inital_state_vector')\n",
    "        \n",
    "# length of observed sequence\n",
    "N = len(obs_seq)\n",
    "\n",
    "# shape path Variables\n",
    "shape = [N, S]\n",
    "shape_ext = [N+1, S]\n",
    "# observed sequence\n",
    "x = tf.constant(obs_seq, dtype=tf.int32, name='observation_sequence')\n",
    "\n",
    "forward = tf.Variable(tf.zeros(shape_ext, dtype=tf.float64), name='forward')\n",
    "backward = tf.Variable(tf.zeros(shape_ext, dtype=tf.float64), name='backward')\n",
    "posterior = tf.Variable(tf.zeros(shape, dtype=tf.float64), name='posteriror')\n",
    "\n",
    "obs_prob_seq = tf.gather(E, x)\n",
    "\n",
    "# forward pass\n",
    "forward = tf.scatter_update(forward, 0, T0)\n",
    "\n",
    "for step in range(N):\n",
    "    prev_prob = tf.reshape(forward[step, :], [1, -1])\n",
    "    prior_prob = tf.matmul(prev_prob, T)\n",
    "    forward_score = tf.mul(prior_prob, tf.cast(obs_prob_seq[step, :], tf.float64))\n",
    "    # Normalize score into a probability\n",
    "    forward_prob = tf.reshape(forward_score / tf.reduce_sum(forward_score), [-1])\n",
    "    # Update forward matrix\n",
    "    forward = tf.scatter_update(forward, step + 1, forward_prob)\n",
    "\n",
    "# backward pass\n",
    "backward = tf.scatter_update(backward, N, tf.ones([S], dtype=tf.float64)) \n",
    "\n",
    "for step in range(N, 0, -1):\n",
    "    next_prob = tf.reshape(backward[step, :], [-1, 1])\n",
    "    obs_prob = tf.diag(obs_prob_seq[step - 1, :])\n",
    "    prior_prob = tf.matmul(T, obs_prob)\n",
    "    backward_score = tf.matmul(prior_prob, next_prob)\n",
    "    backward_prob = tf.reshape(backward_score / tf.reduce_sum(backward_score), [-1])\n",
    "    \n",
    "    # Update backward matrix\n",
    "    backward = tf.scatter_update(backward, step - 1, backward_prob)\n",
    "\n",
    "forward = tf.slice(forward, [1,0], [5,2])\n",
    "backward = tf.slice(backward, [0,0], [5,2])\n",
    "\n",
    "# combine and normalize\n",
    "posterior = tf.mul(forward, backward)\n",
    "a= tf.reduce_sum(posterior, 1)\n",
    "posterior = posterior / tf.reshape(a, [-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9,  0.2],\n",
       "       [ 0.9,  0.2],\n",
       "       [ 0.1,  0.8],\n",
       "       [ 0.9,  0.2],\n",
       "       [ 0.9,  0.2]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.initialize_all_variables())\n",
    "obs_prob_seq.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.89183984,  0.10816016]]),\n",
       " array([[ 0.91668737,  0.08331263]]),\n",
       " array([[ 0.12443362,  0.87556638]]),\n",
       " array([[ 0.83650094,  0.16349906]]),\n",
       " array([[ 0.91668737,  0.08331263]])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_model = HMMTensorflow(trans, p0)\n",
    "\n",
    "y = emi[obs_seq]\n",
    "p, f, b = tf_model.forward_backward(y)\n",
    "[tf.Session().run(g) for g in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.81818182,  0.18181818]]),\n",
       " array([[ 0.88335704,  0.11664296]]),\n",
       " array([[ 0.19066794,  0.80933206]]),\n",
       " array([[ 0.730794,  0.269206]]),\n",
       " array([[ 0.86733889,  0.13266111]])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tf.Session().run(g) for g in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.64693556,  0.35306444]]),\n",
       " array([[ 0.5923176,  0.4076824]]),\n",
       " array([[ 0.37626718,  0.62373282]]),\n",
       " array([[ 0.65334282,  0.34665718]]),\n",
       " array([[ 0.62727273,  0.37272727]])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tf.Session().run(g) for g in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most likely States:  ['umbrella', 'umbrella', 'no_umbrella', 'umbrella', 'umbrella']\n",
      "\n",
      "         0          1          2          3          4\n",
      "rain: 0.89184 0.91668 0.12443 0.83650 0.91668\n",
      "no_rain: 0.10816 0.08331 0.87556 0.16349 0.08331\n",
      "\n",
      "Most likely States:  ['umbrella', 'umbrella', 'no_umbrella', 'umbrella', 'umbrella']\n",
      "\n",
      "         0          1          2          3          4\n",
      "rain: 0.81818 0.88335 0.19066 0.73079 0.86733\n",
      "no_rain: 0.18181 0.11664 0.80933 0.26920 0.13266\n",
      "\n",
      "Most likely States:  ['umbrella', 'umbrella', 'no_umbrella', 'umbrella', 'umbrella']\n",
      "\n",
      "         0          1          2          3          4\n",
      "rain: 0.64693 0.59231 0.37626 0.65334 0.62727\n",
      "no_rain: 0.35306 0.40768 0.62373 0.34665 0.37272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np_model = HMMNumpy(trans, p0)\n",
    "\n",
    "y = emi[obs_seq]\n",
    "results = np_model.forward_backward(y)\n",
    "for pathScores in results:\n",
    "    np_states = np.argmax(pathScores, axis=1)\n",
    "    print(\"Most likely States: \",[obs[s] for s in np_states])\n",
    "    print()\n",
    "    dptable(pathScores)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
