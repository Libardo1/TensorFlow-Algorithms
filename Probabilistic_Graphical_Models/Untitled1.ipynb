{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class HiddenMarkovModel(object):\n",
    "\n",
    "    \"\"\"\n",
    "    Hidden Markov Model Class\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    \n",
    "    - S: Number of states.\n",
    "    - T: Transition matrix of size S by S\n",
    "         stores probability from state i to state j.\n",
    "    - E: Emission matrix of size S by N (number of observations)\n",
    "         stores the probability of observing  O_j  from state  S_i. \n",
    "    - T0: Initial state probabilities of size S.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, T, E, T0, epsilon, maxStep = 10):\n",
    "        \n",
    "        # Max number of iteration\n",
    "        self.maxStep = maxStep\n",
    "        \n",
    "        # convergence criteria\n",
    "        self.epsilon = epsilon \n",
    "        \n",
    "        # Number of possible states\n",
    "        self.S = T.shape[0]\n",
    "        \n",
    "        # Number of possible observations\n",
    "        self.O = E.shape[0]\n",
    "        \n",
    "        # Emission probability\n",
    "        self.E = tf.Variable(E, dtype=tf.float64, name='emission_matrix')\n",
    "\n",
    "        # Transition matrix\n",
    "        self.T = tf.Variable(T, dtype=tf.float64, name='transition_matrix')\n",
    "\n",
    "        # Initial state vector\n",
    "        self.T0 = tf.Variable(tf.constant(T0, dtype=tf.float64, name='inital_state_vector'))\n",
    "    \n",
    "    def initialize_variables(self, shape):\n",
    "        self.forward = tf.Variable(tf.zeros(shape, dtype=tf.float64), name='forward')\n",
    "        self.backward = tf.Variable(tf.zeros(shape, dtype=tf.float64), name='backward')\n",
    "        self.posterior = tf.Variable(tf.zeros(shape, dtype=tf.float64), name='posteriror')\n",
    "\n",
    "\n",
    "    def _forward(self, obs_prob_list):\n",
    "        \n",
    "        self.scale = tf.Variable(tf.zeros([self.N], tf.float64)) #scale factors\n",
    "        \n",
    "        # initialize with state starting priors\n",
    "        init_prob = tf.mul(self.T0, tf.squeeze(obs_prob_list[0]))\n",
    "        \n",
    "        # scaling factor at t=0\n",
    "        self.scale = tf.scatter_update(self.scale, 0, 1.0 / tf.reduce_sum(init_prob))\n",
    "\n",
    "        # scaled belief at t=0\n",
    "        self.forward = tf.scatter_update(self.forward, 0, self.scale[0] * init_prob)\n",
    "\n",
    "        # propagate belief\n",
    "        for step, obs_prob in enumerate(obs_prob_list[1:]):\n",
    "            # previous state probability\n",
    "            prev_prob = tf.expand_dims(self.forward[step, :], 0)\n",
    "            # transition prior\n",
    "            prior_prob = tf.matmul(prev_prob, self.T)\n",
    "            # forward belief propagation\n",
    "            forward_score = tf.mul(prior_prob, tf.squeeze(obs_prob))\n",
    "\n",
    "            forward_prob = tf.squeeze(forward_score)\n",
    "            # scaling factor\n",
    "            self.scale = tf.scatter_update(self.scale, step+1, 1.0 / tf.reduce_sum(forward_prob))\n",
    "            # Update forward matrix\n",
    "            self.forward = tf.scatter_update(self.forward, step+1, self.scale[step+1] * forward_prob)\n",
    "        \n",
    "\n",
    "    def _backward(self, obs_prob_list):\n",
    "        # initialize with state ending priors\n",
    "        self.backward = tf.scatter_update(self.backward, 0, self.scale[self.N-1] * tf.ones([self.S], dtype=tf.float64)) \n",
    "\n",
    "        # propagate belief\n",
    "        for step, obs_prob in enumerate(obs_prob_list[:-1]):\n",
    "            # next state probability\n",
    "            next_prob = tf.expand_dims(self.backward[step, :], 1)\n",
    "            # observation emission probabilities\n",
    "            obs_prob_d = tf.diag(tf.squeeze(obs_prob))\n",
    "            # transition prior\n",
    "            prior_prob = tf.matmul(self.T, obs_prob_d)\n",
    "            # backward belief propagation\n",
    "            backward_score = tf.matmul(prior_prob, next_prob)\n",
    "\n",
    "            backward_prob = tf.squeeze(backward_score)\n",
    "\n",
    "            # Update backward matrix\n",
    "            self.backward = tf.scatter_update(self.backward, step+1, self.scale[self.N-2-step] * backward_prob)\n",
    "        \n",
    "        self.backward = tf.assign(self.backward, tf.reverse(self.backward, [True, False]))\n",
    "\n",
    "        \n",
    "    def _posterior(self):\n",
    "        # posterior score\n",
    "        self.posterior = tf.mul(self.forward, self.backward)\n",
    "\n",
    "        marginal = tf.reduce_sum(self.posterior, 1)\n",
    "        self.posterior = self.posterior / tf.expand_dims(marginal, 1)       \n",
    "        \n",
    "        \n",
    "    def re_estimate_emission(self, x):\n",
    "        \n",
    "        states_marginal = tf.reduce_sum(self.gamma, 0)\n",
    "        seq_one_hot = tf.one_hot(tf.cast(x, tf.int64), self.O, 1, 0)\n",
    "        emission_score = tf.matmul(tf.cast(seq_one_hot, tf.float64), self.gamma, transpose_a=True)\n",
    "        return emission_score / states_marginal\n",
    "    \n",
    "    def re_estimate_transition(self, x):\n",
    "        \n",
    "        self.M = tf.Variable(tf.zeros((self.N-1, self.S, self.S), tf.float64))\n",
    "        \n",
    "        for t in range(self.N - 1):\n",
    "            tmp_0 = tf.matmul(tf.expand_dims(self.forward[t, :], 0), self.T)\n",
    "            tmp_1 = tf.mul(tmp_0, tf.expand_dims(tf.gather(self.E, x[t+1]), 0))\n",
    "            denom = tf.squeeze(tf.matmul(tmp_1, tf.expand_dims(self.backward[t+1, :], 1)))\n",
    "\n",
    "            trans_re_estimate = tf.Variable(tf.zeros((self.S, self.S), tf.float64))\n",
    "            for i in range(self.S):\n",
    "                numer = self.forward[t, i] * self.T[i, :] * tf.gather(self.E, x[t+1]) * self.backward[t+1, :]\n",
    "                trans_re_estimate = tf.scatter_update(trans_re_estimate, i, numer / denom)\n",
    "\n",
    "            self.M = tf.scatter_update(self.M, t, trans_re_estimate)\n",
    "\n",
    "        self.gamma = tf.squeeze(tf.reduce_sum(self.M, 2))\n",
    "\n",
    "        T0_new = self.gamma[0,:]\n",
    "        T_new = tf.reduce_sum(self.M, 0) / tf.expand_dims(tf.reduce_sum(self.gamma, 0), 1)\n",
    "        \n",
    "        prod = tf.expand_dims(tf.mul(self.forward[self.N-1, :], self.backward[self.N-1, :]), 0)\n",
    "        s= prod/ tf.reduce_sum(prod)\n",
    "        self.gamma = tf.concat(0, [self.gamma, s])\n",
    "        \n",
    "        return T0_new, T_new\n",
    "    \n",
    "    def check_convergence(self, new_T0, new_transition, new_emission):\n",
    "        \n",
    "        delta_T0 = tf.reduce_max(tf.abs(self.T0 - new_T0)) < self.epsilon\n",
    "        delta_T = tf.reduce_max(tf.abs(self.T - new_transition)) < self.epsilon\n",
    "        delta_E = tf.reduce_max(tf.abs(self.E - new_emission)) < self.epsilon\n",
    "\n",
    "        return tf.logical_and(tf.logical_and(delta_T0, delta_T), delta_E)\n",
    "        \n",
    "    def forward_backward(self, obs_prob_seq):\n",
    "        \"\"\"\n",
    "        runs forward backward algorithm on observation sequence\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        - obs_seq : matrix of size N by S, where N is number of timesteps and\n",
    "            S is the number of states\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        - forward : matrix of size N by S representing\n",
    "            the forward probability of each state at each time step\n",
    "        - backward : matrix of size N by S representing\n",
    "            the backward probability of each state at each time step\n",
    "        - posterior : matrix of size N by S representing\n",
    "            the posterior probability of each state at each time step\n",
    "        \"\"\"\n",
    "        obs_prob_list_for = tf.split(0, self.N, obs_prob_seq)\n",
    "        \n",
    "        # forward belief propagation\n",
    "        self._forward(obs_prob_list_for)\n",
    "\n",
    "        obs_prob_seq_rev = tf.reverse(obs_prob_seq, [True, False])\n",
    "        obs_prob_list_back = tf.split(0, self.N, obs_prob_seq_rev)\n",
    "\n",
    "        # backward belief propagation\n",
    "        self._backward(obs_prob_list_back)\n",
    "        \n",
    "    def expectation_maximization_step(self, x):\n",
    "        \n",
    "        # probability of emission sequence\n",
    "        obs_prob_seq = tf.gather(self.E, x)\n",
    "\n",
    "        self.forward_backward(obs_prob_seq)\n",
    "\n",
    "        new_T0, new_transition = self.re_estimate_transition(x)\n",
    "\n",
    "        new_emission = self.re_estimate_emission(x)\n",
    "\n",
    "        converged = self.check_convergence(new_T0, new_transition, new_emission)\n",
    "\n",
    "        self.T0 = tf.assign(self.T0, new_T0)\n",
    "        self.E = tf.assign(self.E, new_emission)\n",
    "        self.T = tf.assign(self.T, new_transition)\n",
    "        #self.count = tf.assign_add(self.count, 1)\n",
    "        return converged\n",
    "        \n",
    "    \n",
    "    def Baum_Welch_EM(self, obs_seq):\n",
    "        \n",
    "        # length of observed sequence\n",
    "        self.N = len(obs_seq)\n",
    "\n",
    "        # shape of Variables\n",
    "        shape = [self.N, self.S]\n",
    "        \n",
    "        # observed sequence\n",
    "        x = tf.constant(obs_seq, dtype=tf.int32, name='observation_sequence')\n",
    "        \n",
    "        # initialize variables\n",
    "        self.initialize_variables(shape)\n",
    "        \n",
    "        converged = tf.cast(False, tf.bool)\n",
    "        #self.count = tf.Variable(tf.constant(0))\n",
    "        \n",
    "        for _ in range(self.maxStep):\n",
    "            converged = self.expectation_maximization_step(x)\n",
    "\n",
    "#         TF while_loop op is buggy, should be fixed in future release\n",
    "#         def loop_conditions(converged, obs_seq):\n",
    "#             cond_1 = tf.logical_not(converged)\n",
    "#             cond_2 = tf.less(self.count, self.maxStep)\n",
    "#             return tf.logical_or(cond_1, cond_2)\n",
    "        \n",
    "#         def body(converged, obs_seq):\n",
    "#             return self.expectation_maximization_step(obs_seq)\n",
    "        \n",
    "#         while_params = [converged, obs_seq]\n",
    "#         c = tf.while_loop(loop_conditions, body, while_params)\n",
    "      \n",
    "        return self.T, self.E, converged\n",
    "    \n",
    "    def run_Baum_Welch_EM(self, obs_seq):\n",
    "        with tf.Session() as sess:\n",
    "            \n",
    "            transition, emission, converged = self.Baum_Welch_EM(obs_seq)\n",
    "            sess.run(tf.initialize_all_variables())\n",
    "            return sess.run([transition, emission, converged])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_HMM_observation(num_obs, pi, T, E):\n",
    "    def drawFrom(probs):\n",
    "        return np.where(np.random.multinomial(1,probs) == 1)[0][0]\n",
    "\n",
    "    obs = np.zeros(num_obs)\n",
    "    states = np.zeros(num_obs)\n",
    "    states[0] = drawFrom(pi)\n",
    "    obs[0] = drawFrom(E[:, int(states[0])])\n",
    "    for t in range(1,num_obs):\n",
    "        states[t] = drawFrom(T[int(states[t-1]),:])\n",
    "        obs[t] = drawFrom(E[:, int(states[t])])\n",
    "    return obs, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "True_pi = np.array([0.3, 0.7])\n",
    "\n",
    "True_T = np.array([[0.15, 0.85],\n",
    "                  [0.88, 0.12]])\n",
    "\n",
    "True_E = np.array([[0.6, 0.4],\n",
    "                   [0.2, 0.3],\n",
    "                   [0.2, 0.3]])\n",
    "\n",
    "obs_seq = [ 0,  2,  2,  1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obs_seq, states = generate_HMM_observation(50, True_pi, True_T, True_E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  2.  2.  2.  0.  0.  2.  0.  0.  0.  0.  2.  0.  0.  0.  0.  1.  0.\n",
      "  0.  0.  0.  2.  2.  0.  2.  2.  0.  2.  1.  0.  0.  2.  0.  0.  0.  0.\n",
      "  1.  0.  2.  0.  1.  0.  2.  0.  0.  1.  2.  1.  0.  1.]\n",
      "[ 1.  0.  1.  0.  1.  0.  1.  0.  1.  0.  1.  1.  0.  1.  0.  1.  0.  1.\n",
      "  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  0.  0.\n",
      "  1.  1.  1.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(obs_seq)\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.14310236  0.85689764]\n",
      " [ 0.98208363  0.01791637]]\n",
      "\n",
      "[[  7.01661351e-01   4.40458357e-01]\n",
      " [  6.20388901e-09   3.00575475e-01]\n",
      " [  2.98338643e-01   2.58966168e-01]]\n",
      "\n",
      "True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model =  HiddenMarkovModel(True_T, True_E, True_pi, 0.0001, 20)\n",
    "\n",
    "results = model.run_Baum_Welch_EM(obs_seq)\n",
    "for i in results:\n",
    "    print(i)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#         # length of observed sequence\n",
    "#         self.N = len(obs_seq)\n",
    "\n",
    "#         # shape of Variables\n",
    "#         shape = [self.N, self.S]\n",
    "        \n",
    "#         # observed sequence\n",
    "#         x = tf.constant(obs_seq, dtype=tf.int32, name='observation_sequence')\n",
    "        \n",
    "#         # initialize variables\n",
    "#         self.initialize_variables(shape)\n",
    "        \n",
    "#         converged = tf.cast(False, tf.bool)\n",
    "#         count = 0\n",
    "        #while tf.logical_or(converged, tf.greater_equal(count, self.maxStep)):\n",
    "        #while converged:\n",
    "        \n",
    "        \n",
    "#         obs_prob_list_for = tf.split(0, self.N, obs_prob_seq)\n",
    "\n",
    "#         # forward belief propagation\n",
    "#         self._forward(obs_prob_list_for)\n",
    "\n",
    "#         obs_prob_seq_rev = tf.reverse(obs_prob_seq, [True, False])\n",
    "#         obs_prob_list_back = tf.split(0, self.N, obs_prob_seq_rev)\n",
    "\n",
    "#         # backward belief propagation\n",
    "#         self._backward(obs_prob_list_back)\n",
    "\n",
    "        # apply smoothing\n",
    "#         self._posterior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.constant(results[2], tf.float64)\n",
    "N = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.44914801,  0.55085199],\n",
       "       [ 0.51414077,  0.48585923],\n",
       "       [ 0.49190764,  0.50809236]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gamma = tf.squeeze(tf.reduce_sum(x, 2))\n",
    "prod = tf.expand_dims(tf.mul(model.forward[N-1, :], model.backward[N-1, :]), 0)\n",
    "sess.run(tf.initialize_all_variables())\n",
    "#s= prod/ tf.reduce_sum(prod)\n",
    "#gamma = tf.concat(0, [gamma, s])\n",
    "p0_new = gamma[0,:]\n",
    "T_new = tf.reduce_sum(x, 0) / tf.expand_dims(tf.reduce_sum(gamma, 0), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.11872303,  0.88127697],\n",
       "       [ 0.84598158,  0.15401842]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_new.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum(xi,2) / np.sum(gamma[:,:-1],axis=1).reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prod =  (alpha[:,nSamples-1] * beta[:,nSamples-1]).reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.17391304,  1.54746686,  2.0845962 ,  4.26083044])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if np.max(abs(pi - newpi)) < criterion and \\\n",
    "       np.max(abs(A - newA)) < criterion and \\\n",
    "       np.max(abs(B - newB)) < criterion:\n",
    "    done = 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use the logical TensorFlow ops to test the value of a tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-71d2227ef5de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT_new\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT_new\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT_new\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/marvinbertin/anaconda/envs/TensorFlow-env/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m       \u001b[0;34m`\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m     \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m     raise TypeError(\"Using a `tf.Tensor` as a Python `bool` is not allowed. \"\n\u001b[0m\u001b[1;32m    476\u001b[0m                     \u001b[0;34m\"Use `if t is not None:` instead of `if t:` to test if a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                     \u001b[0;34m\"tensor is defined, and use the logical TensorFlow ops \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use the logical TensorFlow ops to test the value of a tensor."
     ]
    }
   ],
   "source": [
    "epsilon = 0.5\n",
    "tf.reduce_max(T_new) < epsilon and \\\n",
    "tf.reduce_max(T_new) < epsilon and \\\n",
    "tf.reduce_max(T_new) < epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-6f398b0acb1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdelta_T0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnew_T0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdelta_T\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnew_transition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdelta_E\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnew_emission\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "epsilon = 0.5\n",
    "delta_T0 = tf.reduce_max(tf.abs(self.T0 - new_T0)) < epsilon\n",
    "delta_T = tf.reduce_max(tf.abs(self.T - new_transition)) < epsilon\n",
    "delta_E = tf.reduce_max(tf.abs(self.E - new_emission)) < epsilon\n",
    "\n",
    "converged = tf.logical_and(tf.logical_and(delta_T0, delta_T), delta_E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.logical_and(tf.logical_and(True, False), True).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Less_7:0' shape=() dtype=bool>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.less(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.cast(False, tf.bool).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
