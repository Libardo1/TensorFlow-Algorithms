{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class HiddenMarkovModel(object):\n",
    "\n",
    "    \"\"\"\n",
    "    Hidden Markov Model Class\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    \n",
    "    - S: Number of states.\n",
    "    - T: Transition matrix of size S by S\n",
    "         stores probability from state i to state j.\n",
    "    - E: Emission matrix of size S by N (number of observations)\n",
    "         stores the probability of observing  O_j  from state  S_i. \n",
    "    - T0: Initial state probabilities of size S.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, T, E, T0, epsilon, maxStep = 10):\n",
    "        \n",
    "        with tf.name_scope('Inital_Parameters'):\n",
    "            with tf.name_scope('Scalar_constants'):\n",
    "                # Max number of iteration\n",
    "                self.maxStep = maxStep\n",
    "\n",
    "                # convergence criteria\n",
    "                self.epsilon = epsilon \n",
    "\n",
    "                # Number of possible states\n",
    "                self.S = T.shape[0]\n",
    "\n",
    "                # Number of possible observations\n",
    "                self.O = E.shape[0]\n",
    "\n",
    "            with tf.name_scope('Model_Parameters'):\n",
    "                # Emission probability\n",
    "                self.E = tf.Variable(E, dtype=tf.float64, name='emission_matrix')\n",
    "\n",
    "                # Transition matrix\n",
    "                self.T = tf.Variable(T, dtype=tf.float64, name='transition_matrix')\n",
    "\n",
    "                # Initial state vector\n",
    "                self.T0 = tf.Variable(tf.constant(T0, dtype=tf.float64, name='inital_state_vector'))\n",
    "    \n",
    "    def initialize_variables(self, shape):\n",
    "        self.forward = tf.Variable(tf.zeros(shape, dtype=tf.float64), name='forward')\n",
    "        self.backward = tf.Variable(tf.zeros(shape, dtype=tf.float64), name='backward')\n",
    "        self.posterior = tf.Variable(tf.zeros(shape, dtype=tf.float64), name='posteriror')\n",
    "\n",
    "\n",
    "    def _forward(self, obs_prob_list):\n",
    "        \n",
    "        with tf.name_scope('init_scaling_factor'):\n",
    "            self.scale = tf.Variable(tf.zeros([self.N], tf.float64)) #scale factors\n",
    "        \n",
    "        with tf.name_scope('forward_first_step'):\n",
    "            # initialize with state starting priors\n",
    "            init_prob = tf.mul(self.T0, tf.squeeze(obs_prob_list[0]))\n",
    "\n",
    "            # scaling factor at t=0\n",
    "            self.scale = tf.scatter_update(self.scale, 0, 1.0 / tf.reduce_sum(init_prob))\n",
    "\n",
    "            # scaled belief at t=0\n",
    "            self.forward = tf.scatter_update(self.forward, 0, self.scale[0] * init_prob)\n",
    "\n",
    "        # propagate belief\n",
    "        for step, obs_prob in enumerate(obs_prob_list[1:]):\n",
    "            with tf.name_scope('time_step-%s' %step):\n",
    "                # previous state probability\n",
    "                prev_prob = tf.expand_dims(self.forward[step, :], 0)\n",
    "                # transition prior\n",
    "                prior_prob = tf.matmul(prev_prob, self.T)\n",
    "                # forward belief propagation\n",
    "                forward_score = tf.mul(prior_prob, tf.squeeze(obs_prob))\n",
    "\n",
    "                forward_prob = tf.squeeze(forward_score)\n",
    "                # scaling factor\n",
    "                self.scale = tf.scatter_update(self.scale, step+1, 1.0 / tf.reduce_sum(forward_prob))\n",
    "                # Update forward matrix\n",
    "                self.forward = tf.scatter_update(self.forward, step+1, self.scale[step+1] * forward_prob)\n",
    "        \n",
    "\n",
    "    def _backward(self, obs_prob_list):\n",
    "        with tf.name_scope('backward_last_step'):\n",
    "            # initialize with state ending priors\n",
    "            self.backward = tf.scatter_update(self.backward, 0, self.scale[self.N-1] * tf.ones([self.S], dtype=tf.float64)) \n",
    "\n",
    "        # propagate belief\n",
    "        for step, obs_prob in enumerate(obs_prob_list[:-1]):\n",
    "            with tf.name_scope('time_step-%s' %step):\n",
    "                # next state probability\n",
    "                next_prob = tf.expand_dims(self.backward[step, :], 1)\n",
    "                # observation emission probabilities\n",
    "                obs_prob_d = tf.diag(tf.squeeze(obs_prob))\n",
    "                # transition prior\n",
    "                prior_prob = tf.matmul(self.T, obs_prob_d)\n",
    "                # backward belief propagation\n",
    "                backward_score = tf.matmul(prior_prob, next_prob)\n",
    "\n",
    "                backward_prob = tf.squeeze(backward_score)\n",
    "\n",
    "                # Update backward matrix\n",
    "                self.backward = tf.scatter_update(self.backward, step+1, self.scale[self.N-2-step] * backward_prob)\n",
    "        \n",
    "        self.backward = tf.assign(self.backward, tf.reverse(self.backward, [True, False]))\n",
    "\n",
    "        \n",
    "    def _posterior(self):\n",
    "        # posterior score\n",
    "        self.posterior = tf.mul(self.forward, self.backward)\n",
    "\n",
    "        marginal = tf.reduce_sum(self.posterior, 1)\n",
    "        self.posterior = self.posterior / tf.expand_dims(marginal, 1)       \n",
    "        \n",
    "        \n",
    "    def re_estimate_emission(self, x):\n",
    "        \n",
    "        states_marginal = tf.reduce_sum(self.gamma, 0)\n",
    "        seq_one_hot = tf.one_hot(tf.cast(x, tf.int64), self.O, 1, 0)\n",
    "        emission_score = tf.matmul(tf.cast(seq_one_hot, tf.float64), self.gamma, transpose_a=True)\n",
    "        return emission_score / states_marginal\n",
    "    \n",
    "    def re_estimate_transition(self, x):\n",
    "        \n",
    "        with tf.name_scope('Init_3D_tensor'):\n",
    "            self.M = tf.Variable(tf.zeros((self.N-1, self.S, self.S), tf.float64))\n",
    "        \n",
    "        with tf.name_scope('3D_tensor_transition'):\n",
    "            for t in range(self.N - 1):\n",
    "                with tf.name_scope('time_step-%s' %t):\n",
    "                    tmp_0 = tf.matmul(tf.expand_dims(self.forward[t, :], 0), self.T)\n",
    "                    tmp_1 = tf.mul(tmp_0, tf.expand_dims(tf.gather(self.E, x[t+1]), 0))\n",
    "                    denom = tf.squeeze(tf.matmul(tmp_1, tf.expand_dims(self.backward[t+1, :], 1)))\n",
    "\n",
    "                with tf.name_scope('Init_new_transition'):\n",
    "                    trans_re_estimate = tf.Variable(tf.zeros((self.S, self.S), tf.float64))\n",
    "                    \n",
    "                for i in range(self.S):\n",
    "                    with tf.name_scope('State-%s' %i):\n",
    "                        numer = self.forward[t, i] * self.T[i, :] * tf.gather(self.E, x[t+1]) * self.backward[t+1, :]\n",
    "                        trans_re_estimate = tf.scatter_update(trans_re_estimate, i, numer / denom)\n",
    "\n",
    "                self.M = tf.scatter_update(self.M, t, trans_re_estimate)\n",
    "\n",
    "        with tf.name_scope('Smooth_gamma'):\n",
    "            self.gamma = tf.squeeze(tf.reduce_sum(self.M, 2))\n",
    "            T_new = tf.reduce_sum(self.M, 0) / tf.expand_dims(tf.reduce_sum(self.gamma, 0), 1)\n",
    "        \n",
    "        with tf.name_scope('New_init_states_prob'):\n",
    "            T0_new = self.gamma[0,:]\n",
    "\n",
    "        with tf.name_scope('Append_gamma_final_time_step'):\n",
    "            prod = tf.expand_dims(tf.mul(self.forward[self.N-1, :], self.backward[self.N-1, :]), 0)\n",
    "            s= prod/ tf.reduce_sum(prod)\n",
    "            self.gamma = tf.concat(0, [self.gamma, s])\n",
    "        \n",
    "        return T0_new, T_new\n",
    "    \n",
    "    def check_convergence(self, new_T0, new_transition, new_emission):\n",
    "        \n",
    "        delta_T0 = tf.reduce_max(tf.abs(self.T0 - new_T0)) < self.epsilon\n",
    "        delta_T = tf.reduce_max(tf.abs(self.T - new_transition)) < self.epsilon\n",
    "        delta_E = tf.reduce_max(tf.abs(self.E - new_emission)) < self.epsilon\n",
    "\n",
    "        return tf.logical_and(tf.logical_and(delta_T0, delta_T), delta_E)\n",
    "        \n",
    "    def forward_backward(self, obs_prob_seq):\n",
    "        \"\"\"\n",
    "        runs forward backward algorithm on observation sequence\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        - obs_seq : matrix of size N by S, where N is number of timesteps and\n",
    "            S is the number of states\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        - forward : matrix of size N by S representing\n",
    "            the forward probability of each state at each time step\n",
    "        - backward : matrix of size N by S representing\n",
    "            the backward probability of each state at each time step\n",
    "        - posterior : matrix of size N by S representing\n",
    "            the posterior probability of each state at each time step\n",
    "        \"\"\"\n",
    "        obs_prob_list_for = tf.split(0, self.N, obs_prob_seq)\n",
    "        \n",
    "        with tf.name_scope('forward_belief_propagation'):\n",
    "            # forward belief propagation\n",
    "            self._forward(obs_prob_list_for)\n",
    "\n",
    "        obs_prob_seq_rev = tf.reverse(obs_prob_seq, [True, False])\n",
    "        obs_prob_list_back = tf.split(0, self.N, obs_prob_seq_rev)\n",
    "\n",
    "        with tf.name_scope('backward_belief_propagation'):\n",
    "            # backward belief propagation\n",
    "            self._backward(obs_prob_list_back)\n",
    "        \n",
    "    def expectation_maximization_step(self, x):\n",
    "        \n",
    "        # probability of emission sequence\n",
    "        obs_prob_seq = tf.gather(self.E, x)\n",
    "\n",
    "        with tf.name_scope('Forward_Backward'):\n",
    "            self.forward_backward(obs_prob_seq)\n",
    "\n",
    "        with tf.name_scope('Re_estimate_transition'):\n",
    "            new_T0, new_transition = self.re_estimate_transition(x)\n",
    "        \n",
    "        with tf.name_scope('Re_estimate_emission'):\n",
    "            new_emission = self.re_estimate_emission(x)\n",
    "\n",
    "        with tf.name_scope('Check_Convergence'):\n",
    "            converged = self.check_convergence(new_T0, new_transition, new_emission)\n",
    "\n",
    "        with tf.name_scope('Update_parameters'):\n",
    "            self.T0 = tf.assign(self.T0, new_T0)\n",
    "            self.E = tf.assign(self.E, new_emission)\n",
    "            self.T = tf.assign(self.T, new_transition)\n",
    "            #self.count = tf.assign_add(self.count, 1)\n",
    "             \n",
    "            with tf.name_scope('histogram_summary'):\n",
    "                _ = tf.histogram_summary(self.T0.name, self.T0)\n",
    "                _ = tf.histogram_summary(self.T.name, self.T)\n",
    "                _ = tf.histogram_summary(self.E.name, self.E)\n",
    "        return converged\n",
    "        \n",
    "    \n",
    "    def Baum_Welch_EM(self, obs_seq):\n",
    "        \n",
    "        with tf.name_scope('Input_Observed_Sequence'):\n",
    "            # length of observed sequence\n",
    "            self.N = len(obs_seq)\n",
    "\n",
    "            # shape of Variables\n",
    "            shape = [self.N, self.S]\n",
    "\n",
    "            # observed sequence\n",
    "            x = tf.constant(obs_seq, dtype=tf.int32, name='observation_sequence')\n",
    "        \n",
    "        with tf.name_scope('Initialize_variables'):\n",
    "            # initialize variables\n",
    "            self.initialize_variables(shape)\n",
    "        \n",
    "        converged = tf.cast(False, tf.bool)\n",
    "        #self.count = tf.Variable(tf.constant(0))\n",
    "        \n",
    "        with tf.name_scope('Train_Baum_Welch'):\n",
    "            for i in range(self.maxStep):\n",
    "                \n",
    "                with tf.name_scope('EM_step-%s' %i):\n",
    "                    converged = self.expectation_maximization_step(x)\n",
    "\n",
    "#         TF while_loop op is buggy, should be fixed in future release\n",
    "#         def loop_conditions(converged, obs_seq):\n",
    "#             cond_1 = tf.logical_not(converged)\n",
    "#             cond_2 = tf.less(self.count, self.maxStep)\n",
    "#             return tf.logical_or(cond_1, cond_2)\n",
    "        \n",
    "#         def body(converged, obs_seq):\n",
    "#             return self.expectation_maximization_step(obs_seq)\n",
    "        \n",
    "#         while_params = [converged, obs_seq]\n",
    "#         c = tf.while_loop(loop_conditions, body, while_params)\n",
    "      \n",
    "        return self.T0, self.T, self.E, converged\n",
    "    \n",
    "    def run_Baum_Welch_EM(self, obs_seq, summary=False):\n",
    "        \n",
    "        trans0, transition, emission, converged = self.Baum_Welch_EM(obs_seq)\n",
    "        \n",
    "        # Build the summary operation based on the TF collection of Summaries.\n",
    "        summary_op = tf.merge_all_summaries()\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            \n",
    "            sess.run(tf.initialize_all_variables())\n",
    "            t0, T, E, c = sess.run([trans0, transition, emission, converged])\n",
    "            \n",
    "            if summary:\n",
    "                # Instantiate a SummaryWriter to output summaries and the Graph.\n",
    "                summary_writer = tf.train.SummaryWriter('logs/', graph=sess.graph)\n",
    "                \n",
    "                summary_str = sess.run(summary_op)\n",
    "                summary_writer.add_summary(summary_str)\n",
    "\n",
    "            return t0, T, E, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_HMM_observation(num_obs, pi, T, E):\n",
    "    def drawFrom(probs):\n",
    "        return np.where(np.random.multinomial(1,probs) == 1)[0][0]\n",
    "\n",
    "    obs = np.zeros(num_obs)\n",
    "    states = np.zeros(num_obs)\n",
    "    states[0] = drawFrom(pi)\n",
    "    obs[0] = drawFrom(E[:, int(states[0])])\n",
    "    for t in range(1,num_obs):\n",
    "        states[t] = drawFrom(T[int(states[t-1]),:])\n",
    "        obs[t] = drawFrom(E[:, int(states[t])])\n",
    "    return obs, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "True_pi = np.array([0.4, 0.6])\n",
    "\n",
    "True_T = np.array([[0.85, 0.15],\n",
    "                  [0.12, 0.88]])\n",
    "\n",
    "True_E = np.array([[0.6, 0.2],\n",
    "                   [0.3, 0.5],\n",
    "                   [0.1, 0.3]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obs_seq, states = generate_HMM_observation(10, True_pi, True_T, True_E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  0.  2.  2.  2.  2.  1.  1.  2.]\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(obs_seq)\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_pi = np.array([0.5, 0.5])\n",
    "\n",
    "init_T = np.array([[0.4, 0.6],\n",
    "                  [0.7, 0.3]])\n",
    "\n",
    "init_E = np.array([[0.4, 0.2],\n",
    "                   [0.3, 0.5],\n",
    "                   [0.3, 0.3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.02662428  0.97337572]\n",
      "\n",
      "[[ 0.58855654  0.41144346]\n",
      " [ 0.58059463  0.41940537]]\n",
      "\n",
      "[[ 0.16413039  0.0280103 ]\n",
      " [ 0.21006766  0.61320891]\n",
      " [ 0.62580194  0.35878078]]\n",
      "\n",
      "True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model =  HiddenMarkovModel(init_T, init_E, init_pi, epsilon=0.0001, maxStep=10)\n",
    "\n",
    "results = model.run_Baum_Welch_EM(obs_seq, summary=True)\n",
    "for i in results:\n",
    "    print(i)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#         # length of observed sequence\n",
    "#         self.N = len(obs_seq)\n",
    "\n",
    "#         # shape of Variables\n",
    "#         shape = [self.N, self.S]\n",
    "        \n",
    "#         # observed sequence\n",
    "#         x = tf.constant(obs_seq, dtype=tf.int32, name='observation_sequence')\n",
    "        \n",
    "#         # initialize variables\n",
    "#         self.initialize_variables(shape)\n",
    "        \n",
    "#         converged = tf.cast(False, tf.bool)\n",
    "#         count = 0\n",
    "        #while tf.logical_or(converged, tf.greater_equal(count, self.maxStep)):\n",
    "        #while converged:\n",
    "        \n",
    "        \n",
    "#         obs_prob_list_for = tf.split(0, self.N, obs_prob_seq)\n",
    "\n",
    "#         # forward belief propagation\n",
    "#         self._forward(obs_prob_list_for)\n",
    "\n",
    "#         obs_prob_seq_rev = tf.reverse(obs_prob_seq, [True, False])\n",
    "#         obs_prob_list_back = tf.split(0, self.N, obs_prob_seq_rev)\n",
    "\n",
    "#         # backward belief propagation\n",
    "#         self._backward(obs_prob_list_back)\n",
    "\n",
    "        # apply smoothing\n",
    "#         self._posterior()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
